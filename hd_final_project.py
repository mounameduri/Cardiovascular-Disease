# -*- coding: utf-8 -*-
"""HD FINAL project.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1nupzih1LWZp3NO8-GwtMYPKb4XNwc-Ub
"""

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import numpy as np
import pickle
data=pd.read_csv('Heart_Disease.csv') #read the dataset
data.head()

data.shape

data.target.value_counts()

data.isna().sum()

import seaborn as sns
sns.countplot(x=data["target"])

categorical_val = []
continous_val = []
for column in data.columns:
    if len(data[column].unique())<=9:
        categorical_val.append(column)
    else:
        continous_val.append(column)

categorical_val

continous_val

plt.figure(figsize=(15, 15))
plt.suptitle("Categorical Feature Distributions by Heart Disease Status")
for i, column in enumerate(categorical_val, 1):
    plt.subplot(3, 3, i)
    data[data["target"] == 0][column].hist(bins=35, color='blue', label='Have Heart Disease = NO', alpha=0.6)
    data[data["target"] == 1][column].hist(bins=35, color='red', label='Have Heart Disease = YES', alpha=0.6)
    plt.legend()
    plt.xlabel(column)

plt.figure(figsize=(15, 15))
plt.suptitle("Continuous Feature Distributions by Heart Disease Status")
for i, column in enumerate(continous_val, 1):
    plt.subplot(3, 3, i)
    data[data["target"] == 0][column].hist(bins=35, color='blue', label='Have Heart Disease = NO', alpha=0.6)
    data[data["target"] == 1][column].hist(bins=35, color='red', label='Have Heart Disease = YES', alpha=0.6)
    plt.legend()
    plt.xlabel(column)

categorical_val.remove('target')
dataset = pd.get_dummies(data, columns = categorical_val)

dataset.head()

print(data.columns)
print(dataset.columns)

from sklearn.preprocessing import StandardScaler
s_sc = StandardScaler()
col_to_scale = ['age', 'trestbps', 'chol', 'thalach', 'oldpeak']
dataset[col_to_scale] = s_sc.fit_transform(dataset[col_to_scale])

dataset.head()

from sklearn.model_selection import train_test_split
X = dataset.drop('target', axis=1) #features

y = dataset.target #target
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42) #split into train and test

from sklearn.linear_model import LogisticRegression
from sklearn import metrics
lr_clf = LogisticRegression()
lr_clf.fit(X_train, y_train)
y_pred1=lr_clf.predict(X_test)
print('Accuracy: ',metrics.accuracy_score(y_test, y_pred1))

from sklearn.metrics import classification_report,confusion_matrix
print(classification_report(y_test, y_pred1))

print(confusion_matrix(y_test, y_pred1))

conf_matrix=confusion_matrix(y_test, y_pred1)

fig, ax = plt.subplots(figsize=(7.5, 7.5))
ax.matshow(conf_matrix, cmap=plt.cm.Blues, alpha=0.3)
for i in range(conf_matrix.shape[0]):
    for j in range(conf_matrix.shape[1]):
        ax.text(x=j, y=i,s=conf_matrix[i, j], va='center', ha='center', size='xx-large')

plt.xlabel('Predictions', fontsize=18)
plt.ylabel('Actuals', fontsize=18)
plt.title('Confusion Matrix', fontsize=18)
plt.show()

#import the KNeighborsClassifier class from sklearn
from sklearn.neighbors import KNeighborsClassifier
k_range = range(1,26) #1-25
scores = {}
scores_list = []
for k in k_range:
        knn = KNeighborsClassifier(n_neighbors=k)  #model building
        knn.fit(X_train,y_train) #training
        y_pred2=knn.predict(X_test) #testing
        scores[k] = metrics.accuracy_score(y_test,y_pred2)
        scores_list.append(metrics.accuracy_score(y_test,y_pred2))

scores

knn = KNeighborsClassifier(n_neighbors=19)
knn.fit(X_train,y_train)  #model is trained
y_pred2=knn.predict(X_test)
print('Accuracy: ',metrics.accuracy_score(y_test, y_pred2))

print(classification_report(y_test, y_pred2))

print(confusion_matrix(y_test, y_pred2))

pickle.dump(knn, open('heartmodel.pkl', 'wb'))

#implementation of support vector machine
from sklearn.svm import SVC
clf=SVC(kernel='rbf',C=100,gamma=0.001) #model creation
clf.fit(X_train,y_train) #training the model
y_pred3=clf.predict(X_test) #predicting the data using the model
print('Accuracy: ',metrics.accuracy_score(y_test, y_pred3)) #finding the accuracy

from sklearn.tree import DecisionTreeClassifier
dt_clf = DecisionTreeClassifier(random_state=42)
dt_clf.fit(X_train, y_train)
y_pred3 = dt_clf.predict(X_test)
print('Accuracy: ', metrics.accuracy_score(y_test, y_pred3))
print(classification_report(y_test, y_pred3))
conf_matrix = confusion_matrix(y_test, y_pred3)
fig, ax = plt.subplots(figsize=(7.5, 7.5))
ax.matshow(conf_matrix, cmap=plt.cm.Blues, alpha=0.3)
for i in range(conf_matrix.shape[0]):
    for j in range(conf_matrix.shape[1]):
        ax.text(x=j, y=i, s=conf_matrix[i, j], va='center', ha='center', size='xx-large')

from sklearn.ensemble import RandomForestClassifier
rf_clf = RandomForestClassifier(random_state=42)
rf_clf.fit(X_train, y_train)
y_pred4 = rf_clf.predict(X_test)
print('Accuracy: ', metrics.accuracy_score(y_test, y_pred4))
print(classification_report(y_test, y_pred4))
conf_matrix = confusion_matrix(y_test, y_pred4)
fig, ax = plt.subplots(figsize=(7.5, 7.5))
ax.matshow(conf_matrix, cmap=plt.cm.Blues, alpha=0.3)
for i in range(conf_matrix.shape[0]):
    for j in range(conf_matrix.shape[1]):
        ax.text(x=j, y=i, s=conf_matrix[i, j], va='center', ha='center', size='xx-large')

plt.xlabel('Predictions', fontsize=18)
plt.ylabel('Actuals', fontsize=18)
plt.title('Confusion Matrix - Random Forest', fontsize=18)
plt.show()

from sklearn.model_selection import GridSearchCV
param_grid={'C':[0.1,1.0,10.0,100.0,1000.0],
           'gamma':[1,0.1,0.01,0.001,0,0.0001],
           'kernel':['linear', 'poly', 'rbf', 'sigmoid']}

grid=GridSearchCV(SVC(),param_grid,refit=True,verbose=3)
grid.fit(X_train, y_train)

print(grid.best_params_)

print(grid.best_estimator_)

from sklearn.ensemble import RandomForestClassifier
rf_clf = RandomForestClassifier(max_depth=8, max_features='log2', n_estimators=300)
rf_clf.fit(X_train, y_train)
y_pred4=rf_clf.predict(X_test)
print('Accuracy: ',metrics.accuracy_score(y_test, y_pred4))

param_grid={
    'n_estimators':[100,200,300,400,500],
    'max_features':['auto','log2','sqrt'],
    'max_depth':[4,5,6,7,8],
    'criterion':['gini','entropy']
}

grid=GridSearchCV(RandomForestClassifier(),param_grid,refit=True,verbose=3)
grid.fit(X_train, y_train)

print(grid.best_params_)

print(grid.best_estimator_)

y_pred1 = lr_clf.predict(X_test)
results_df = pd.DataFrame(data=[["Logistic Regression", metrics.accuracy_score(y_test, y_pred1)]],
                          columns=['Model', 'Accuracy'])
results_df

y_pred2 = knn.predict(X_test)
results_df_1 = pd.DataFrame(data=[["K-nearest neighbors",metrics.accuracy_score(y_test, y_pred2)]],
                          columns=['Model','Accuracy'])
#results_df = results_df.append(results_df_2, ignore_index=True)
results_df_1

y_pred3 = clf.predict(X_test)
results_df_2 = pd.DataFrame(data=[["SVM",metrics.accuracy_score(y_test, y_pred3)]],
                          columns=['Model','Accuracy'])
results_df_2

y_pred4 = rf_clf.predict(X_test)
results_df_3 = pd.DataFrame(data=[["Random Forest",metrics.accuracy_score(y_test, y_pred4)]],
                          columns=['Model','Accuracy'])

results_df_3

from sklearn.metrics import classification_report, confusion_matrix

models = {
    "KNN": (y_pred2, knn.predict_proba(X_test)[:, 1]),
    "Random Forest": (y_pred4, rf_clf.predict_proba(X_test)[:, 1]),
    "SVM": (y_pred3, clf.decision_function(X_test)),  # SVM uses decision_function
    "Logistic Regression": (y_pred1, lr_clf.predict_proba(X_test)[:, 1])
}

for name, (y_pred, y_scores) in models.items():
    print(f"\n--- {name} ---")
    print("Accuracy:", metrics.accuracy_score(y_test, y_pred))
    print("ROC AUC:", roc_auc_score(y_test, y_scores))
    print(classification_report(y_test, y_pred))
    print("Confusion Matrix:\n", confusion_matrix(y_test, y_pred))

from sklearn.metrics import roc_curve, roc_auc_score
plt.figure(figsize=(10, 8))
for name, (_, y_scores) in models.items():
    fpr, tpr, _ = roc_curve(y_test, y_scores)
    auc = roc_auc_score(y_test, y_scores)
    plt.plot(fpr, tpr, label=f"{name} (AUC = {auc:.2f})")

plt.plot([0, 1], [0, 1], 'k--', label="Random Guess (AUC = 0.5)")
plt.xlabel("False Positive Rate (FPR)")
plt.ylabel("True Positive Rate (TPR)")
plt.title("ROC Curve Comparison")
plt.legend(loc="lower right")
plt.show()

import pickle
pickle.dump(knn, open('best_model.pkl', 'wb'))